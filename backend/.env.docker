NODE_ENV=production
PORT=3001

# CORS for local Next.js (adjust as needed)
CORS_ORIGIN=http://localhost:3033

# n8n inside docker network (service name)
N8N_WEBHOOK_URL=http://n8n:5678/webhook/ai-assistant
ASSISTANT_FALLBACK_MESSAGE=Iâ€™m online and ready. If you see this message, n8n is starting; try again in a few seconds.

# Optional LLM (OpenAI-compatible) for general Q&A like ChatGPT
# Uncomment and set your key to enable. Examples:
# OpenAI   -> LLM_PROVIDER=openai,   LLM_MODEL=gpt-4o-mini
# OpenRouter-> LLM_PROVIDER=openrouter (set LLM_BASE_URL if needed)
# Groq     -> LLM_PROVIDER=groq
# Together -> LLM_PROVIDER=together
# DeepSeek -> LLM_PROVIDER=deepseek
#LLM_API_KEY=replace_with_your_key
#LLM_MODEL=gpt-4o-mini
#LLM_PROVIDER=openai
#LLM_BASE_URL=

# Tesseract/Poppler optional if you use Python OCR outside container
TESSERACT_PATH=/usr/bin/tesseract
POPPLER_PATH=/usr/bin
